{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP: Import lagom\n",
    "# Not useful once lagom is installed\n",
    "import sys\n",
    "sys.path.append('/home/zuoxingdong/Documents/Code/lagom/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([Discrete(2), Discrete(3)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lagom.envs.spaces import Box, Dict, Discrete\n",
    "\n",
    "s = Dict({'position': Discrete(2), 'velocity': Discrete(3)})\n",
    "s.spaces.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PartialFlattenDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartialFlattenDictWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, dict_keys):\n",
    "\n",
    "        # Figure out observation_space dimension.\n",
    "        size = 0\n",
    "        for key in dict_keys:\n",
    "            shape = self.env.observation_space.spaces[key].shape\n",
    "            size += np.prod(shape)\n",
    "        self.observation_space = gym.spaces.Box(-np.inf, np.inf, shape=(size,), dtype='float32')\n",
    "\n",
    "    def observation(self, observation):\n",
    "        assert isinstance(observation, dict)\n",
    "        obs = []\n",
    "        for key in self.dict_keys:\n",
    "            obs.append(observation[key].ravel())\n",
    "        return np.concatenate(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VecEnv(object):\n",
    "    \"\"\"\n",
    "    An asynchronous, vectorized environment. \n",
    "    \"\"\"\n",
    "    def __init__(self, num_envs, observation_space, action_space):\n",
    "        self.num_envs = num_envs\n",
    "        self.observation_space = observation_space\n",
    "        self.action_space = action_space\n",
    "       \n",
    "    def step_async(self, actions):\n",
    "        \"\"\"\n",
    "        All environments take a step with the given actions. \n",
    "        \n",
    "        Call step_wait() to obtain the outputs. \n",
    "        \n",
    "        Note: Do not call this function when a step_async is pending\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def step_wait(self):\n",
    "        \"\"\"\n",
    "        Wait for step_async(). \n",
    "        \n",
    "        Returns:\n",
    "            observations (array): single or a tuple of observations\n",
    "            rewards (array): rewards\n",
    "            dones (array): booleans of episode terminations\n",
    "            infos (array): info objects\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def step(self, actions):\n",
    "        self.step_async(actions)\n",
    "        \n",
    "        return self.step_wait()\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset all environments and returns a tuple of observations. \n",
    "        \n",
    "        step_async() will be cancelled. \n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def render(self):\n",
    "        pass\n",
    "        \n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Closing the environments\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @property\n",
    "    def observation_space(self):\n",
    "        \"\"\"\n",
    "        Return a Space object to define the observation space.\n",
    "        \"\"\"\n",
    "        return self.observation_space\n",
    "    \n",
    "    @property\n",
    "    def action_space(self):\n",
    "        \"\"\"\n",
    "        Return a Space object to define the action space.\n",
    "        \"\"\"\n",
    "        return self.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyVecEnv(VecEnv):\n",
    "    def __init__(self, list_make_env):\n",
    "        self.envs = [make_env() for make_env in list_make_env]\n",
    "        observation_space = self.envs[0].observation_space\n",
    "        action_space = self.envs[0].action_space\n",
    "        super().__init__(len(list_make_env), observation_space, action_space)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyVecEnv(VecEnv):\n",
    "    def __init__(self, env_fns):\n",
    "        \n",
    "        obs_spaces = self.observation_space.spaces if isinstance(self.observation_space, gym.spaces.Tuple) else (self.observation_space,)\n",
    "        self.buf_obs = [np.zeros((self.num_envs,) + tuple(s.shape), s.dtype) for s in obs_spaces]\n",
    "        self.buf_dones = np.zeros((self.num_envs,), dtype=np.bool)\n",
    "        self.buf_rews  = np.zeros((self.num_envs,), dtype=np.float32)\n",
    "        self.buf_infos = [{} for _ in range(self.num_envs)]\n",
    "        self.actions = None\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        self.actions = actions\n",
    "\n",
    "    def step_wait(self):\n",
    "        for i in range(self.num_envs):\n",
    "            obs_tuple, self.buf_rews[i], self.buf_dones[i], self.buf_infos[i] = self.envs[i].step(self.actions[i])\n",
    "            if self.buf_dones[i]:\n",
    "                obs_tuple = self.envs[i].reset()\n",
    "            if isinstance(obs_tuple, (tuple, list)):\n",
    "                for t,x in enumerate(obs_tuple):\n",
    "                    self.buf_obs[t][i] = x\n",
    "            else:\n",
    "                self.buf_obs[0][i] = obs_tuple\n",
    "        return (self._obs_from_buf(), np.copy(self.buf_rews), np.copy(self.buf_dones),\n",
    "                self.buf_infos.copy())\n",
    "\n",
    "    def reset(self):\n",
    "        for i in range(self.num_envs):\n",
    "            obs_tuple = self.envs[i].reset()\n",
    "            if isinstance(obs_tuple, (tuple, list)):\n",
    "                for t,x in enumerate(obs_tuple):\n",
    "                    self.buf_obs[t][i] = x\n",
    "            else:\n",
    "                self.buf_obs[0][i] = obs_tuple\n",
    "        return self._obs_from_buf()\n",
    "\n",
    "    def close(self):\n",
    "        return\n",
    "\n",
    "    def _obs_from_buf(self):\n",
    "        if len(self.buf_obs) == 1:\n",
    "            return np.copy(self.buf_obs[0])\n",
    "        else:\n",
    "            return tuple(np.copy(x) for x in self.buf_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Process  # easier code than threading\n",
    "from multiprocessing import Pipe  # Much faster than Queue\n",
    "\n",
    "\n",
    "class CloudpickleWrapper(object):\n",
    "    \"\"\"\n",
    "    Uses cloudpickle to serialize contents (otherwise multiprocessing tries to use pickle)\n",
    "    \"\"\"\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.x()\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        import cloudpickle\n",
    "        return cloudpickle.dumps(self.x)\n",
    "    def __setstate__(self, ob):\n",
    "        import pickle\n",
    "        self.x = pickle.loads(ob)\n",
    "\n",
    "\n",
    "def worker(child_conn, parent_conn, make_env):\n",
    "    parent_conn.close()\n",
    "    # Create an environment\n",
    "    env = make_env()\n",
    "    \n",
    "    while True:\n",
    "        cmd, data = child_conn.recv()\n",
    "        if cmd == 'step':\n",
    "            obs, reward, done, info = env.step(data)\n",
    "            if done:\n",
    "                obs = env.reset()  # TODO: why reset\n",
    "            child_conn.send([obs, reward, done, info])\n",
    "        elif cmd == 'reset':\n",
    "            obs = env.reset()\n",
    "            child_conn.send(obs)\n",
    "        elif cmd == 'reset_task':\n",
    "            obs = env.reset_task()\n",
    "            child_conn.send(obs)\n",
    "        elif cmd == 'close':\n",
    "            child_conn.close()\n",
    "            break\n",
    "        elif cmd == 'get_spaces':\n",
    "            child_conn.send([env.observation_space, env.action_space])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "class SubprocVecEnv(VecEnv):\n",
    "    \"\"\"\n",
    "    Run a list of environment in subprocesses\n",
    "    \"\"\"\n",
    "    def __init__(self, list_make_env):\n",
    "        self.waiting = False\n",
    "        self.closed = False\n",
    "        self.num_envs = len(list_make_env)\n",
    "        self.parent_conns, self.child_conns = zip(*[Pipe() for _ in range(self.num_envs)])\n",
    "        self.processes = []\n",
    "        for parent_conn, child_conn, make_env in zip(self.parent_conns, self.child_conns, list_make_env):\n",
    "            self.processes.append(Process(target=worker, args=[child_conn, parent_conn, CloudpickleWrapper(make_env)]))  # TODO: CloudpickleWrapper make_env\n",
    "        for process in self.processes:\n",
    "            process.daemon = True  # if the main process crashes, we should not cause things to hang\n",
    "            process.start()\n",
    "        for conn in self.child_conns:\n",
    "            conn.close()\n",
    "        \n",
    "        # Obtain observation and action spaces\n",
    "        self.parent_conns[0].send(['get_spaces', None])\n",
    "        observation_space, action_space = self.parent_conns[0].recv()\n",
    "        super().__init__(self.num_envs, observation_space, action_space)\n",
    "        \n",
    "    def step_asyn(self, actions):\n",
    "        for parent_conn, action in zip(self.parent_conns, actions):\n",
    "            parent_conn.send(['step', action])\n",
    "            \n",
    "        self.waiting = True\n",
    "        \n",
    "    def step_wait(self):\n",
    "        observations, rewards, dones, infos = zip(*[parent_conn.recv() for parent_conn in self.parent_conns])\n",
    "        self.waiting = False\n",
    "        return np.stack(observations), np.stack(rewards), np.stack(dones), infos\n",
    "    \n",
    "    def reset(self):\n",
    "        for parent_conn in self.parent_conns:\n",
    "            parent_conn.send(['reset', None])\n",
    "        return np.stack([parent_conn.recv() for parent_conn in self.parent_conns])\n",
    "    \n",
    "    def reset_task(self):\n",
    "        for parent_conn in self.parent_conns:\n",
    "            parent_conn.send(['reset_task', None])\n",
    "        return np.stack([parent_conn.recv() for parent_conn in self.parent_conns])\n",
    "    \n",
    "    def close(self):\n",
    "        if self.closed:\n",
    "            return\n",
    "        if self.waiting:\n",
    "            for parent_conn in self.parent_conns:\n",
    "                parent_conn.recv()\n",
    "        for parent_conn in self.parent_conns:\n",
    "            parent_conn.send(['close', None])\n",
    "        for process in self.processes:\n",
    "            process.join()\n",
    "        self.closed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional neural networks, from DeepMind Nature paper. \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 input_channel, \n",
    "                 conv_kernels,\n",
    "                 conv_kernel_sizes,\n",
    "                 conv_strides, \n",
    "                 conv_pads, \n",
    "                 conv_nonlinearity, \n",
    "                 hidden_sizes, \n",
    "                 hidden_nonlinearity, \n",
    "                 output_dim=None, \n",
    "                 output_nonlinearity=None):\n",
    "        \"\"\"\n",
    "        Set up CNN with configurations. \n",
    "        \n",
    "        Args:\n",
    "            input_channel (int): the number of channels of the input, e.g. color channel\n",
    "            conv_kernels (list): a list of number of kernels (filters or feature maps), for each convolutional layer. \n",
    "            conv_kernel_sizes (list): a list of kernel sizes, [int or tuple], for each convolutional layer. \n",
    "            conv_strides (list): a list of strides, for each convolutional layer. \n",
    "            conv_pads (list): a list of paddings, for each convolutional layer. \n",
    "            conv_nonlinearity (nn.functional): nonlinearity for convolutional layers\n",
    "            hidden_sizes (list): a list of sizes for hidden layers\n",
    "            hidden_nonlinearity (nn.functional): nonlinearity for hidden layers\n",
    "            output_dim (int): output dimension\n",
    "                                If None, then no output layer to be generated (useful if output has different heads)\n",
    "            output_nonlinearity (nn.functional): nonlinearity for output layer\n",
    "                                If None, then no output nonlinearity\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_channel = input_channel \n",
    "        self.conv_kernels = conv_kernels\n",
    "        self.conv_kernel_sizes = conv_kernel_sizes\n",
    "        self.conv_strides = conv_strides\n",
    "        self.conv_pads = conv_pads \n",
    "        self.conv_nonlinearity = conv_nonlinearity\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.hidden_nonlinearity = hidden_nonlinearity\n",
    "        self.output_dim = output_dim\n",
    "        self.output_nonlinearity = output_nonlinearity\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "T = 20\n",
    "L = 1000\n",
    "N = 100\n",
    "\n",
    "x = np.empty((N, L), 'int64')\n",
    "x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)\n",
    "data = np.sin(x/T).astype('float32')\n",
    "\n",
    "\n",
    "class Sequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm1 = nn.LSTMCell(1, 51)\n",
    "        self.lstm2 = nn.LSTMCell(51, 51)\n",
    "        self.linear = nn.Linear(51, 1)\n",
    "        \n",
    "    def forward(self, x, future=0):\n",
    "        outputs = []\n",
    "        batch_size, x_size = x.size()\n",
    "        \n",
    "        h_t = torch.zeros(batch_size, 51)\n",
    "        c_t = torch.zeros(batch_size, 51)\n",
    "        h_t_2 = torch.zeros(batch_size, 51)\n",
    "        c_t_2 = torch.zeros(batch_size, 51)\n",
    "        \n",
    "        chunks = x.chunk(x_size, dim=1)\n",
    "        \n",
    "        for x_t in chunks:\n",
    "            h_t, c_t = self.lstm1(x_t, (h_t, c_t))\n",
    "            h_t_2, c_t_2 = self.lstm2(h_t, (h_t_2, c_t_2))\n",
    "            \n",
    "            output = self.linear(h_t_2)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            \n",
    "        for _ in range(future):  # if we should predict the future\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t_2, c_t_2 = self.lstm2(h_t, (h_t_2, c_t_2))\n",
    "            \n",
    "            output = self.linear(h_t_2)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            \n",
    "        outputs = torch.stack(outputs, dim=1).squeeze(2)\n",
    "        \n",
    "        return outputs\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    input = torch.from_numpy(data[3:, :-1])\n",
    "    target = torch.from_numpy(data[3:, 1:])\n",
    "    test_input = torch.from_numpy(data[:3, :-1])\n",
    "    test_target = torch.from_numpy(data[:3, 1:])\n",
    "\n",
    "    seq = Sequence()\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Use LBFGS since we load whole data to train\n",
    "    optimizer = optim.LBFGS(seq.parameters(), lr=0.8)\n",
    "\n",
    "    for i in range(2):\n",
    "        print(f'STEP: {i}')\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            out = seq(input)\n",
    "            loss = criterion(out, target)\n",
    "            print(f'Loss: {loss.item()}')\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        optimizer.step(closure)\n",
    "\n",
    "        # Prediction\n",
    "        future = 1000\n",
    "        pred = seq(test_input, future=future)\n",
    "        loss = criterion(pred[:, :-future], test_target)\n",
    "        print(f'Test loss: {loss.item()}')\n",
    "        y = pred.data.numpy()\n",
    "\n",
    "        # Drawing\n",
    "        plt.figure(figsize=(30, 10))\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.xticks(fontsize=20)\n",
    "        plt.yticks(fontsize=20)\n",
    "        def draw(yi, color):\n",
    "            plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth=2.0)\n",
    "            plt.plot(np.arange(input.size(1), input.size(1)+future), yi[input.size(1):], color + ':', linewidth=2.0)\n",
    "        draw(y[0], 'r')\n",
    "        draw(y[1], 'g')\n",
    "        draw(y[2], 'b')\n",
    "        \n",
    "        plt.savefig(f'logs/{i}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
