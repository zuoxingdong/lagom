{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zuo/Code/tmp/lagom/lagom/vis/__init__.py:11: UserWarning: ImageViewer failed to import due to pyglet. \n",
      "  warnings.warn('ImageViewer failed to import due to pyglet. ')\n",
      "/home/zuo/Code/tmp/lagom/lagom/envs/vec_env.py:12: UserWarning: ImageViewer failed to import due to pyglet. \n",
      "  warnings.warn('ImageViewer failed to import due to pyglet. ')\n"
     ]
    }
   ],
   "source": [
    "from lagom.envs import make_vec_env\n",
    "from lagom.envs import wrap_atari\n",
    "import gym\n",
    "from agent import Agent\n",
    "\n",
    "\n",
    "env = make_vec_env(lambda: wrap_atari(gym.make('PongNoFrameskip-v4')), 1, 0)\n",
    "agent = Agent({'agent.replay_size': 10, 'agent.eps_train': 10, 'agent.eps_decay_period': 1, \n",
    "               'agent.min_replay_history': 100, 'agent.lr': 1e-3, 'agent.batch_size': 32,\n",
    "              'agent.gamma': 0.99, 'agent.max_grad_norm': 40}, env, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0166, -0.0166, -0.0384,  0.0003,  0.0302,  0.0060]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "agent.q_net(torch.from_numpy(np.asarray(env.reset())).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2632,  0.9043],\n",
      "        [ 0.8153,  0.5093],\n",
      "        [-0.3550,  0.3992]])\n",
      "tensor([0, 0, 1])\n",
      "tensor([0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3, 2)\n",
    "print(a)\n",
    "print(a.argmax(-1))\n",
    "print(a.max(-1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay_buffer import ReplayBuffer\n",
    "from lagom import RandomAgent\n",
    "\n",
    "env = make_vec_env(lambda: wrap_atari(gym.make('PongNoFrameskip-v4')), 1, 0)\n",
    "\n",
    "replay = ReplayBuffer(30)\n",
    "agent = RandomAgent(None, env, 'cpu')\n",
    "\n",
    "def initialize_replay(config, agent, env, replay):\n",
    "    random_agent = RandomAgent(None, env, None)\n",
    "    observation = env.reset()\n",
    "    for t in range(config['agent.min_replay_history']):\n",
    "        action = agent.choose_action(observation)['raw_action']\n",
    "        next_observation, reward, done, info = env.step(action)\n",
    "        [replay.add(observation[i], action[i], reward[i], next_observation[i], done[i]) for i in range(len(env))]\n",
    "        observation = next_observation\n",
    "        if done:\n",
    "            observation = env.reset()\n",
    "            \n",
    "initialize_replay({'agent.min_replay_history': 50}, agent, env, replay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deque(maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]\n",
      "(84, 84, 4)\n",
      "961: done\n",
      "[True]\n",
      "(84, 84, 4)\n",
      "1779: done\n",
      "[True]\n",
      "(84, 84, 4)\n",
      "2811: done\n",
      "deque([-20.0, -21.0, -18.0, -4.0], maxlen=100)\n"
     ]
    }
   ],
   "source": [
    "from lagom.envs import make_vec_env, wrap_atari\n",
    "import gym\n",
    "seed = 0\n",
    "def make_env():\n",
    "    return wrap_atari(gym.make('PongNoFrameskip-v4'))\n",
    "env = make_vec_env(make_env, 1, seed, 'serial')\n",
    "\n",
    "\n",
    "running_rewards = deque([0.0], maxlen=100)\n",
    "env.reset()\n",
    "for i in range(3000):\n",
    "    obs, reward, done, info = env.step([env.action_space.sample()])\n",
    "    running_rewards[-1] += reward[0]\n",
    "    if done[0]:\n",
    "        print(done)\n",
    "        print(info[0]['terminal_observation'].shape)\n",
    "        print(f'{i}: done')\n",
    "        running_rewards.append(0.0)\n",
    "    \n",
    "print(running_rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<AtariEnv<PongNoFrameskip-v4>>>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym.envs.atari.AtariEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [np.random.randn(84, 84, 4) for _ in range(100000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "nn.init.kaiming_uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
